<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.1.2//EN" "http://www.oasis-open.org/docbook/xml/4.1.2/docbookx.dtd">
<article lang="">
  <para>Current Drives:</para>
  <para>Google:</para>
  <para>        CloudGv00 (Myb6tbc)</para>
  <para>                        Family</para>
  <para>                        Kids</para>
  <para>                        MamaBetty</para>
  <para>                        Sue</para>
  <para>MEYE (Myb6tbc)</para>
  <para>notMEGA (Myb6tbc)</para>
  <para>MEGA</para>
  <para>        Videos (Myb12tb)</para>
  <para>                DepthQ_Demo-B_1280x1440_VC-1</para>
  <para>                Kathy</para>
  <para>KathyDVD</para>
  <para>KathyVHS</para>
  <para>                Video1948to1969</para>
  <para>                Video1985to1999</para>
  <para>Video1985</para>
  <para>Video1988</para>
  <para>Video1989</para>
  <para>Video1990</para>
  <para>Video1991</para>
  <para>Video1992</para>
  <para>Video1993</para>
  <para>Video1994</para>
  <para>Video1995</para>
  <para>Video1996</para>
  <para>Video1997</para>
  <para>Video1998</para>
  <para>Video1999</para>
  <para>                Video2000to2009</para>
  <para>Video2000</para>
  <para>Video2001</para>
  <para>Video2002</para>
  <para>Video2003</para>
  <para>Video2004</para>
  <para>Video2005</para>
  <para>Video2006</para>
  <para>Video2007</para>
  <para>Video2008</para>
  <para>Video2009</para>
  <para>                Videos2010to2013</para>
  <para>Video2010</para>
  <para>Video2011</para>
  <para>Video2012</para>
  <para>Video2013</para>
  <para>                Videos        2014to2016</para>
  <para>Video2014</para>
  <para>Video2015</para>
  <para>Video2016</para>
  <para/>
  <para>                Video2017to2019</para>
  <para>Video2017</para>
  <para>Video2018</para>
  <para>Video2019</para>
  <para>                Video2020to2021</para>
  <para>Video2020</para>
  <para>Video2021</para>
  <para>                Video2022toPresent</para>
  <para>Video2022</para>
  <para>Video2023</para>
  <para>        Pictures (Myb6tbc)</para>
  <para>                AllPictures</para>
  <para>                Artin</para>
  <para>                Bianka</para>
  <para>                Mae</para>
  <para>                OldPercyPictures</para>
  <para>                Pic19xxto1999</para>
  <para>                Pic2000to2009</para>
  <para>                Pic2010to2013</para>
  <para>                Pic2014to2016</para>
  <para>                Pic2017to2019</para>
  <para>                Pic2020topresent</para>
  <para/>
  <para>        Share (Myb6tbc)</para>
  <para>                Family</para>
  <para>                Kids</para>
  <para>                MamaBetty</para>
  <para>                Sue</para>
  <para/>
  <para>        Docs (Myb6tbc)</para>
  <para>                MyMusic</para>
  <para>                SierraClub</para>
  <para>                Videodoc</para>
  <para>                MyDocumentsMerge</para>
  <para>                GTKrs</para>
  <para>                Iced</para>
  <para>                Church</para>
  <para>                DadsFiles</para>
  <para>                Johnphone</para>
  <para>                rfoBasic</para>
  <para/>
  <para>        Backup(easystore-8tba)</para>
  <para>                JohnComputer</para>
  <para>JohnComputer20190904</para>
  <para>JohnComputer20200508</para>
  <para>JohnComputer20200715</para>
  <para>JohnComputer20200901</para>
  <para>JohnComputer20201107</para>
  <para/>
  <para/>
  <para/>
  <para>                ElyComputer</para>
  <para>Ely20100131Merge</para>
  <para>ElyCompBkup20190101</para>
  <para>ElyComputer20181006</para>
  <para>ElyComputer20200508</para>
  <para>ElyComputer20200712</para>
  <para>ElyComputer20200901</para>
  <para>ElyComputer20201107</para>
  <para>ElyFiles20190531</para>
  <para>ElyPhone20160604Merge</para>
  <para>                OpticalDiskBackups</para>
  <para>                General</para>
  <para>Backup20210327</para>
  <para>Backup20210625</para>
  <para>Backup20210811</para>
  <para>...</para>
  <para>                Phone</para>
  <para>                Phone20220707</para>
  <para>                ClonezillaBackups</para>
  <para>QUARTERLY BACKUP </para>
  <para>run Dir /s &gt; filelistyyyymmdd.txt</para>
  <para>backup computers using freefilesync (FFS)</para>
  <para>                compare file size</para>
  <para>                export filelist.csv before update</para>
  <para>                update</para>
  <para>                Ely onto 3tb drive </para>
  <para>                John onto 6tba drive</para>
  <para>copy Ely files since last bluray backup to Acer with FFS</para>
  <para>copy John files since last bluray backup to Acer with FFS.</para>
  <para>duplicate delete John files.</para>
  <para>duplicate delete Ely with John</para>
  <para>backup to bluray</para>
  <para>copy backup to cloud</para>
  <para/>
  <para>UPDATE BACKUP DATABASE:</para>
  <para/>
  <para>OPTION A  USING CDTREE:</para>
  <para>take Cdtree EXPORTED XML file</para>
  <para>STEP 1</para>
  <para>convert the Cdtree xml file to UTF-8</para>
  <para>Execute: </para>
  <para/>
  <para>    iconv -f utf-16le -t UTF-8 CdTree20231011all.xml -o convt20231011all.xml</para>
  <para/>
  <para>STEP 2</para>
  <para>using  RUST-ICED PROGRAM cdtxml2csvbar,</para>
  <para>create input file to create database.</para>
  <para/>
  <para>use the above file convt20231011all.xml for xml input will create output file of</para>
  <para/>
  <para>convt20231011all.xml__tmpcvs</para>
  <para/>
  <para>with error message file of </para>
  <para/>
  <para>convt20231011all.xml__tmperr</para>
  <para/>
  <para>STEP 3</para>
  <para>create the database </para>
  <para>Execute:</para>
  <para/>
  <para>      sqlite3 bkinit.db3 &lt; importconvt20231011all.sql 2&gt; bkinitout.txt</para>
  <para/>
  <para>where  importconvt20231011all.sql is</para>
  <para/>
  <para>CREATE TABLE blubackup (</para>
  <para>            refname   TEXT NOT NULL,</para>
  <para>            filename  TEXT NOT NULL,</para>
  <para>            dirname  TEXT NOT NULL,</para>
  <para>            filesize INTEGER NOT NULL,</para>
  <para>            filedate TEXT NOT NULL,</para>
  <para>            md5sum TEXT,</para>
  <para>            locations TEXT ,</para>
  <para>            notes TEXT ,</para>
  <para>            PRIMARY KEY (refname, filename, dirname, filesize));</para>
  <para>.separator |</para>
  <para>.import convt20231011all.xml__tmpcvs blubackup</para>
  <para/>
  <para>use THESE set of steps to add an new backup.</para>
  <para>STEP 5</para>
  <para>since the Cdtree catagories are set by year, just export the current year.</para>
  <para/>
  <para>        CdTree20231209bk2023.xml</para>
  <para/>
  <para>STEP 6</para>
  <para>convert the Cdtree xml file to UTF-8</para>
  <para>Execute: </para>
  <para/>
  <para>        iconv -f utf-16le -t UTF-8 CdTree20231209bk2023.xml -o convtjust2023.xml</para>
  <para/>
  <para>STEP 7</para>
  <para>using  RUST-ICED PROGRAM cdtxml2csvbar,</para>
  <para>create input file to create TEMPORARY database.</para>
  <para/>
  <para>use the above file convtjust2023.xml for xml input will create output file of</para>
  <para/>
  <para>        convtjust2023.xml__tmpcvs</para>
  <para/>
  <para>with error message file of </para>
  <para/>
  <para>        convtjust2023.xml__tmperr</para>
  <para/>
  <para>STEP 8</para>
  <para>edit convtjust2023.xml__tmpcvs and remove all other backups except current.</para>
  <para>        i.e. only keep those with refname of bk20231209-</para>
  <para/>
  <para/>
  <para>STEP 9</para>
  <para>create the temporary database </para>
  <para>Execute:</para>
  <para/>
  <para>        sqlite3 bk1209.db3 &lt; importconvtjust2023.sql 2&gt; bk1209out.txt</para>
  <para/>
  <para>                where  importconvtjust2023.sql is</para>
  <para/>
  <para>                        CREATE TABLE blubackup (</para>
  <para>                                refname   TEXT NOT NULL,</para>
  <para>                                filename  TEXT NOT NULL,</para>
  <para>                                dirname  TEXT NOT NULL,</para>
  <para>                                filesize INTEGER NOT NULL,</para>
  <para>                                filedate TEXT NOT NULL,</para>
  <para>                                md5sum TEXT,</para>
  <para>                                locations TEXT ,</para>
  <para>                                notes TEXT ,</para>
  <para>                                PRIMARY KEY (refname, filename, dirname, filesize));</para>
  <para>                        .separator |</para>
  <para>                        .import convtjust2023.xml__tmpcvs blubackup</para>
  <para/>
  <para>        STEP 10</para>
  <para>DUMP THE Temporary db</para>
  <para>Execute: </para>
  <para/>
  <para>        sqlite3 bk1209.db3 .dump &gt; dumpbk1209.sql</para>
  <para/>
  <para>STEP 11</para>
  <para>make a copy of the current backup database i.e. bkinit.db3</para>
  <para>        Execute:</para>
  <para/>
  <para>        cp -p bkinit.db3 bkinit01.db3</para>
  <para/>
  <para>STEP 12</para>
  <para>insert files into main db</para>
  <para>        Execute:</para>
  <para/>
  <para>        sqlite3 bkinit.db3 &lt; dumpbk1209.sql 2&gt; bk1209insertout.txt</para>
  <para/>
  <para>ignore error of: table blubackup already exists.</para>
  <para/>
  <para>Size of original bkinit01 plus bk1209 should equal size of bkinit.</para>
  <para/>
  <para/>
  <para>use these steps to update backup disc database with md5sum.</para>
  <para>STEP 13</para>
  <para>start running RUST-ICED PROGRAM bkmd5sum</para>
  <para>        load the bluray disc</para>
  <para>        confirm that internal matches handwritten label and it is in the backup disc database</para>
  <para>        the output list is used to update the backup disc database</para>
  <para/>
  <para>STEP 14</para>
  <para>make a copy of   CURRENT DATABASE bkinit.db3</para>
  <para>Execute:</para>
  <para/>
  <para>        cp -p bkinit.db3 bkinit02.db3</para>
  <para/>
  <para>STEP 15</para>
  <para>start running RUST-ICED PROGRAM bklistdbupd01</para>
  <para>        specify the database and the listing from PROGRAM bkmd5sum</para>
  <para>        specify an output directory</para>
  <para>        try test run and review output</para>
  <para>        this is a slow process so start progress button will keep you up to date on run</para>
  <para>        most of the time the dates do not match.</para>
  <para>        Try hour, but some go on to the next day so may have to include date</para>
  <para>        ways of excluding items is to edit the list or add an exclude file (directories only).</para>
  <para>        when happy with test output then run update</para>
  <para/>
  <para>OPTION B  USING JUST BACKUP LIST:</para>
  <para>STEP 1</para>
  <para>start running RUST-ICED PROGRAM bkmd5sum</para>
  <para>        load the bluray disc</para>
  <para>        confirm that internal matches handwritten label and it is in the backup disc database</para>
  <para>        the output list is used to update the backup disc database: bkyyyymmddnn.list</para>
  <para/>
  <para>STEP 2</para>
  <para>create a temporary database using the output list (you can concat them to reduce the number of update runs): bkyyyymmddnn.list</para>
  <para>Execute:</para>
  <para>        sqlite3 bkyyyymmddnn.db3 &lt; importbkyyyymmddnn.sql 2&gt; bkyyyymmddnn.txt</para>
  <para/>
  <para>                where  importbkyyyymmddnn.sql is</para>
  <para/>
  <para>                        CREATE TABLE blubackup (</para>
  <para>                                filename  TEXT NOT NULL,</para>
  <para>                                filesize INTEGER NOT NULL,</para>
  <para>                                filedate TEXT NOT NULL,</para>
  <para>                                dirname  TEXT NOT NULL,</para>
  <para>                                refname   TEXT NOT NULL,</para>
  <para>                                md5sum TEXT,</para>
  <para>                                locations TEXT ,</para>
  <para>                                notes TEXT ,</para>
  <para>                                PRIMARY KEY (refname, filename, dirname, filesize));</para>
  <para>                        .separator |</para>
  <para>                        .import bkyyyymmddnn.list blubackup</para>
  <para/>
  <para>STEP 3</para>
  <para>DUMP THE Temporary database(s)</para>
  <para>Execute: </para>
  <para/>
  <para>        sqlite3 bkyyyymmddnn.db3 .dump &gt; bkyyyymmddnn.sql</para>
  <para/>
  <para>STEP 4</para>
  <para>edit each bkyyyymmddnn.sql do a find</para>
  <para/>
  <para>blubackup</para>
  <para/>
  <para>and replace all with </para>
  <para/>
  <para>blubackup(filename, filesize, filedate, dirname, refname, md5sum, locations, notes)</para>
  <para/>
  <para>Since the table is already created, you can delete the create table section at the top.</para>
  <para/>
  <para>the original database table was defined in a different order.</para>
  <para/>
  <para>STEP 5</para>
  <para>make a copy of the current backup database i.e. bkinit.db3</para>
  <para>        Execute:</para>
  <para/>
  <para>        cp -p bkinit.db3 bkinit01.db3</para>
  <para/>
  <para>STEP 6</para>
  <para>insert files into main db</para>
  <para>        Execute for all temporary databases created:</para>
  <para/>
  <para>        sqlite3 bkinit.db3 &lt; bkyyyymmddnn.sql 2&gt; bkyyyymmddnnsql.txt</para>
  <para/>
  <para>ignore error of: table blubackup already exists.</para>
  <para/>
  <para>Size of original bkinit01 plus bkyyyymmddnn should equal size of bkinit.</para>
  <para/>
  <para>No additional steps since the listings already have the md5sum value.</para>
  <para/>
  <para/>
  <para/>
  <para>HARDDRIVE DATABASE EVALUATION and MAINTAINING</para>
  <para>using hdmd5sum create md5sum listing for all disks.</para>
  <para>Backup files to harddrive and cloud.</para>
  <para/>
  <para>STEP A</para>
  <para>Start with largest file and create database.</para>
  <para>Execute: </para>
  <para/>
  <para>      sqlite3 hdinit.db3 &lt; importhd6tbaJohnComputer.sql 2&gt; hdinitout.txt</para>
  <para/>
  <para>where importhd6tbaJohnComputer.sql is</para>
  <para/>
  <para>CREATE TABLE harddrive (</para>
  <para>            filename  TEXT NOT NULL,</para>
  <para>            filesize INTEGER NOT NULL,</para>
  <para>            filedate TEXT NOT NULL,</para>
  <para>            dirname  TEXT NOT NULL,</para>
  <para>            refname   TEXT NOT NULL,</para>
  <para>            md5sum TEXT ,</para>
  <para>            locations TEXT ,</para>
  <para>            notes TEXT ,</para>
  <para>            PRIMARY KEY (refname, filename, dirname, filesize));</para>
  <para>.separator |</para>
  <para>.import hd6tbaJohnComputer.list harddrive</para>
  <para/>
  <para>STEP B</para>
  <para>next file and create temporary file</para>
  <para>Execute: </para>
  <para/>
  <para>      sqlite3 hdwindowsC.db3 &lt; importhdwindowsC.sql 2&gt; hdwindowsCout.txt</para>
  <para/>
  <para>where importhdwindowsC.sql is</para>
  <para/>
  <para>CREATE TABLE harddrive (</para>
  <para>            filename  TEXT NOT NULL,</para>
  <para>            filesize INTEGER NOT NULL,</para>
  <para>            filedate TEXT NOT NULL,</para>
  <para>            dirname  TEXT NOT NULL,</para>
  <para>            refname   TEXT NOT NULL,</para>
  <para>            md5sum TEXT ,</para>
  <para>            locations TEXT ,</para>
  <para>            notes TEXT ,</para>
  <para>            PRIMARY KEY (refname, filename, dirname, filesize));</para>
  <para>.separator |</para>
  <para>.import hhdwindowsC .list harddrive</para>
  <para/>
  <para>STEP C</para>
  <para>DUMP THE Temporary db</para>
  <para>Execute: </para>
  <para/>
  <para>      sqlite3 hdwindowsC.db3 .dump &gt; dumphdwindowsC.sql</para>
  <para/>
  <para>STEP D</para>
  <para>make a copy of hdinit.db3</para>
  <para>Execute:</para>
  <para/>
  <para>      cp -p hdinit.db3 hdinit01.db3</para>
  <para/>
  <para>STEP E</para>
  <para>insert files into main db</para>
  <para>Execute:</para>
  <para/>
  <para>      sqlite3 hdinit.db3 &lt; dumphdwindowsC.sql 2&gt; hdwindowsCdumpout.txt</para>
  <para/>
  <para>ignore error of: table harddrive already exists.</para>
  <para/>
  <para>Size of original hdinit01 plus hdwindowsC should equal size of hdinit.</para>
  <para/>
  <para>REPEAT STEPS B THROUGH E FOR ALL LISTS.</para>
  <para/>
  <para/>
  <para/>
  <para/>
  <para>OPTION OLD WITH CDTREE:</para>
  <para/>
  <para>cdtree bluray discs</para>
  <para>from cdtree export to xml</para>
  <para>convert xml to character system to utf8 because of rust program compatibility</para>
  <para>file -i cd....xml to get character system which should be utf-16le</para>
  <para>need to convert to utf-8 for rust read it.</para>
  <para>iconv -f utf-16le -t UTF-8 &lt; cd....xml &gt; cd...utf8.xml</para>
  <para>gtk rust program BkupEval03 to convert xml to file.  output is cd....cdlist</para>
  <para>sort file </para>
  <para>sort cd....cdlist -k 1 &gt; cd....cdsort</para>
  <para>get fresh list of all drives:</para>
  <para>gtk rust program BkupEval03 to list harddrive.  output is hd....hdlist</para>
  <para>sort file</para>
  <para>sort hd....hdlist -k 1 &gt; hd....hdsort</para>
  <para>COMPARING CLOUD WITH HARDDRIVE</para>
  <para>Need to run the following terminal commands before using iced program MegaParse</para>
  <para>rclone lsf --files-only -R --csv --format pst /pathofHDdirectory | sort &gt; outputfile1</para>
  <para>but have changed it to not include date (t), because time is off by an hour or minute.</para>
  <para>rclone lsf --files-only -R --csv --format ps /pathofHDdirectory | sort &gt; outputfile1</para>
  <para>(rclone lsf --files-only -R --csv --format ps /media/jp/Myb12tb/MEGA/Video | sort &gt; hdVideo)</para>
  <para><anchor id="__DdeLink__747_2440537802"/>mega-ls -l -r --time-format=ISO6081_WITH_TIME /cloudpathofdirectory &gt; outputfile2</para>
  <para>(mega-ls -l -r --time-format=ISO6081_WITH_TIME /Video &gt; megaVideo)</para>
  <para>iced Run MegaParse</para>
  <para>Run this app using mega outputfile2 as input file</para>
  <para>and the second rclone (without date).</para>
  <para>It will bring up Meld.</para>
  <para>Creates two files: one with datetime and the other without datetime</para>
  <para>Need to run the following terminal command after using MegaParse</para>
  <para>sort targetfile &gt; outputfile3</para>
  <para>compare outputfile1 with outputfile3. I use Meld.</para>
  <para>First compare with out time then try with time.</para>
  <para/>
  <para/>
  <para>In MEGAcmd source, megacmdexecuter.cpp line 1347 &amp; 1447 change 10 to 11, </para>
  <para/>
  <para>mega-login jpercyasnet@yahoo.com  password</para>
  <para>mega-cd Video/Video2022toPresent/Video2023/202310Egypt/pictures</para>
  <para> mega-rm -r pic20231017</para>
  <para/>
  <para>        STEP F2</para>
  <para>                need a program to go through the two databases. Ideally the smaller database as input and search through the other database for filename. Check size, date and md5sum. If md5sum not present output as separate file. And continue. Each will allow 10 locations. If larger, output as other separate file. Location is the reference name plus smd. S for same size. M for same md5sum and d for same date. At least one must exist. If found make sure location does not already exist. Separate locations by comma (,) and smd and location by dash (-)</para>
  <para/>
  <para/>
  <para>TO SEE IF HD &amp; MEGA MATCH</para>
  <para>with time:</para>
  <para>rclone lsf --files-only -R --csv --format pst /pathofHDdirectory | sort &gt; outputfile1</para>
  <para/>
  <para>without time:</para>
  <para/>
  <para>rclone lsf --files-only -R --csv --format ps /pathofHDdirectory | sort &gt; outputfile1</para>
  <para/>
  <para>  mega-login email password</para>
  <para>   this generates list of files takes awhile.</para>
  <para>   if mega-logout, will remove list of files and login will be regenerated.</para>
  <para/>
  <para>  mega-ls -l -r --time-format=ISO6081_WITH_TIME /cloudpathofdirectory &gt; outputfile2"</para>
  <para/>
  <para>  Run MegaParse using outputfile2 as input file and targetfile is output</para>
  <para/>
  <para>  sort targetfile &gt; outputfile3</para>
  <para/>
  <para>  compare outputfile1 with outputfile3. I use Meld (not that good, try old way)</para>
  <para/>
  <para>diff outputfile1 outputfile3 &gt; compare.list</para>
  <para/>
  <para>make program like megaremove to take those files with “&lt;” and prefix them with: </para>
  <para>“mega-rm -r “</para>
  <para/>
  <para/>
  <para/>
  <para/>
  <para/>
  <para/>
  <para/>
  <para/>
  <para>DUPLICATE FILES REMOVAL</para>
  <para/>
  <para>Use fclones dry run output.</para>
  <para>fclones group ./testloc &gt; dups.txt</para>
  <para>fclones remove --keep-path '**/rawvideo/**' -o dryex.txt &lt; dups.txt --dry-run 2&gt;dryrun01.txt</para>
  <para/>
  <para>Generate mega move from output.</para>
  <para> format: mega-mv frompath/name topath</para>
  <para>          no output is generated</para>
  <para>          </para>
  <para>Run mega move.</para>
  <para/>
  <para>If ok, Run fclones move</para>
  <para>fclones move --keep-path '**/rawvideo/**' -o dryex.txt topath &lt; dups.txt 2&gt;dryrun01.txt</para>
  <para/>
  <para>See if HD &amp; MEGA match.</para>
  <para/>
  <para>Delete moved files on both HD &amp; MEGA manually.</para>
  <para> </para>
  <para>/media/jp/AoldNTFS/MyDocuments/BackupSystem/BackUpRestoreWithCloudSystemN13.odt         Page 7 of 7</para>
</article>
